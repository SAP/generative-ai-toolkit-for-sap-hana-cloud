{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain import init_llm\n",
    "\n",
    "llm = init_llm('gpt-4', temperature=0.0, max_tokens=2000) # used to do logical reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define fields for scenario\n",
    "\n",
    "scenario_fields_description = {\n",
    "    \"scenario\": \"Define the task the user wants to perform, e.g. [train_classifier, train_regressor, predict_classifier, predict_regressor, train_timeseries, predict_timeseries]\",\n",
    "    \"algorithm\": \"Define the algorithm to be used, e.g. [linear_regression, logistic_regression, random_forest, gradient_boosting, lstm, cnn, transformer, automl]\",\n",
    "    \"dataset_table\": \"Define the dataset to be used, e.g. [iris, boston, mnist, cifar10, custom_dataset]\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[Prompt] In a machine learning scenario. The user question is \"Train an automl classification model on the iris dataset\". Please find Define the task the user wants to perform, e.g. [train_classifier, train_regressor, predict_classifier, predict_regressor, train_timeseries, predict_timeseries],Define the algorithm to be used, e.g. [linear_regression, logistic_regression, random_forest, gradient_boosting, lstm, cnn, transformer, automl],Define the dataset to be used, e.g. [iris, boston, mnist, cifar10, custom_dataset] from this user question. If so, return them wrapped by html opening and closing tag with the tag name scenario,algorithm,dataset_table respectively. If the user decides not to use them from the question, then return empty string wrapped by html opening and closing tag with the tag name scenario,algorithm,dataset_table respectively. Otherwise, do not return anything.\u001b[0m\n",
      "\u001b[92m[AI] Finding fields...\u001b[0m \u001b[91m<scenario>train_classifier</scenario>\n",
      "<algorithm>automl</algorithm>\n",
      "<dataset_table>iris</dataset_table>\u001b[0m\n",
      "{'scenario': 'train_classifier', 'algorithm': 'automl', 'dataset_table': 'iris'}\n"
     ]
    }
   ],
   "source": [
    "from generative_ai_toolkit_for_sap_hana_cloud.agents.scenario_utility import get_fields_by_llm\n",
    "\n",
    "query = \"Train an automl classification model on the iris dataset\"\n",
    "scenario_details = get_fields_by_llm(query, scenario_fields_description, llm, is_wait_for_rate_limit=True, verbose=True, show_prompt=True)\n",
    "print(scenario_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_fields_description = {\n",
    "    \"key\": \"the key column of the dataset\",\n",
    "    \"label\": \"the label column of the dataset\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d0eb1cc3bcf74d77/chat/completions?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[Prompt] In a machine learning scenario. The user question is \"the key is ID and the label is SPECIES\". Please find the key column of the dataset,the label column of the dataset from this user question. If so, return them wrapped by html opening and closing tag with the tag name key,label respectively. If the user decides not to use them from the question, then return empty string wrapped by html opening and closing tag with the tag name key,label respectively. Otherwise, do not return anything.\u001b[0m\n",
      "\u001b[92m[AI] Finding fields...\u001b[0m \u001b[91mFrom the user question, the key column of the dataset is \"ID\" and the label column of the dataset is \"SPECIES\". \n",
      "\n",
      "So, the return would be:\n",
      "\n",
      "<key>ID</key>\n",
      "<label>SPECIES</label>\u001b[0m\n",
      "{'key': 'ID', 'label': 'SPECIES'}\n"
     ]
    }
   ],
   "source": [
    "query = \"the key is ID and the label is SPECIES\"\n",
    "\n",
    "parameters_details = get_fields_by_llm(query, parameters_fields_description, llm, is_wait_for_rate_limit=True, verbose=True, show_prompt=True)\n",
    "print(parameters_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d91561008ffafece/embeddings?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n",
      " 17%|█▋        | 1/6 [00:01<00:06,  1.36s/it]INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d91561008ffafece/embeddings?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 2/6 [00:01<00:03,  1.13it/s]INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d91561008ffafece/embeddings?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 3/6 [00:02<00:02,  1.49it/s]INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d91561008ffafece/embeddings?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.84it/s]INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d91561008ffafece/embeddings?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n",
      " 83%|████████▎ | 5/6 [00:03<00:00,  2.09it/s]INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d91561008ffafece/embeddings?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n",
      "INFO:hana_ml.ml_base:Executing SQL: CREATE  TABLE \"KNOWLEDGE_TABLE\" (\"id\" VARCHAR(5000) PRIMARY KEY, \"description\" NCLOB, \"example\" NCLOB, \"embeddings\" REAL_VECTOR(1536));\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from generative_ai_toolkit_for_sap_hana_cloud.agents.scenario_agents import _get_scenario_code_template\n",
    "from generative_ai_toolkit_for_sap_hana_cloud.vectorstore.embedding_service import GenAIHubEmbeddings\n",
    "from generative_ai_toolkit_for_sap_hana_cloud.vectorstore.hana_vector_engine import HANAMLinVectorEngine\n",
    "\n",
    "from hana_ml import dataframe\n",
    "url, port, user, pwd = \"hana-ml-api.hana-ml.c.ap-cn-1.cloud.sap\", 30015, \"PAL_TEST\", \"Init1234\"\n",
    "connection_context = dataframe.ConnectionContext(url, port, user, pwd)\n",
    "knowledge_table = \"KNOWLEDGE_TABLE\"\n",
    "\n",
    "knowledge_base = HANAMLinVectorEngine(connection_context, knowledge_table)\n",
    "code_template =  _get_scenario_code_template(\"training\")\n",
    "if code_template is not None:\n",
    "    if not connection_context.has_table(knowledge_table):\n",
    "        knowledge_base.upsert_knowledge(code_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d91561008ffafece/embeddings?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strictly use the Examples to create AutoML instance.\n",
      "Do fitting:\n",
      ">>> from hana_ml.algorithms.pal.auto_ml import AutomaticClassification\n",
      ">>> model_train = AutomaticClassification(generations=2, population_size=5, offspring_size=5, max_eval_time_mins=10, successive_halving=True)\n",
      ">>> model.enable_workload_class(workload_class_name=<WORKLOAD_CLASS>)\n",
      ">>> model_train.fit(data=df, key=<key>, features=<features>, label=<label>)\n",
      ">>> print({\"output table names\": model_train._fit_output_table_names, \"Python object address\": id(model_train)})\n"
     ]
    }
   ],
   "source": [
    "code_template = knowledge_base.query(input=f\"Fields\\n{scenario_details}\", embedding_function=GenAIHubEmbeddings())\n",
    "print(code_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d0eb1cc3bcf74d77/chat/completions?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n",
      "WARNING:hana_ml.algorithms.pal.auto_ml:The workload class name cannot be found in the HANA settings.\n",
      "INFO:hana_ml.ml_base:Executing SQL: DO\n",
      "BEGIN\n",
      "DECLARE param_name VARCHAR(5000) ARRAY;\n",
      "DECLARE int_value INTEGER ARRAY;\n",
      "DECLARE double_value DOUBLE ARRAY;\n",
      "DECLARE string_value VARCHAR(5000) ARRAY;\n",
      "param_name[1] := N'GENERATIONS';\n",
      "int_value[1] := 2;\n",
      "double_value[1] := NULL;\n",
      "string_value[1] := NULL;\n",
      "param_name[2] := N'POPULATION_SIZE';\n",
      "int_value[2] := 5;\n",
      "double_value[2] := NULL;\n",
      "string_value[2] := NULL;\n",
      "param_name[3] := N'OFFSPRING_SIZE';\n",
      "int_value[3] := 5;\n",
      "double_value[3] := NULL;\n",
      "string_value[3] := NULL;\n",
      "param_name[4] := N'CONFIG_DICT';\n",
      "int_value[4] := NULL;\n",
      "double_value[4] := NULL;\n",
      "string_value[4] := N'{\"LabelEncoder\": {\"IGNORE_UNKNOWN\": [1]}, \"OneHotEncoder\": {\"MINIMUM_FRACTION\": [0.05, 0.1, 0.15, 0.2, 0.25], \"IGNORE_UNKNOWN\": [1]}, \"Imputer\": {\"IMPUTATION_TYPE\": [1, 2, 3]}, \"PolynomialFeatures\": {\"MIN_DEGREE\": [1], \"MAX_DEGREE\": [2], \"INTERACTION_ONLY\": [0], \"INCLUDE_BIAS\": [0]}, \"CATPCA\": {\"COMPONENTS_PERCENTAGE\": [0.1, 0.2, 0.5, 0.7, 1.0], \"SCALING\": [1], \"COMPONENT_TOL\": [0.0], \"MAX_ITERATION\": [100], \"CONVERGE_TOL\": [0.0001], \"LANCZOS_ITERATION\": [100], \"SVD_CALCULATOR\": [0]}, \"FS_supervised\": {\"FS_METHOD\": [3], \"TOP_K_BEST\": [10]}, \"HGBT_Classifier\": {\"ITER_NUM\": [10, 100], \"ETA\": [0.1, 0.3], \"MIN_CHILD_HESSIAN\": [1.0], \"MAX_DEPTH\": [4, 10], \"REPLACE_MISSING\": [0], \"FEATURE_GROUPING\": [0], \"CALCULATE_IMPORTANCE\": [0], \"CALCULATE_CONFUSION_MATRIX\": [0]}, \"MLP_Classifier\": {\"ACTIVATION\": [13], \"OUTPUT_ACTIVATION\": [2], \"HIDDEN_LAYER_SIZE\": [\"100\"], \"TRAINING_STYLE\": [0], \"NORMALIZATION\": [1], \"WEIGHT_INIT\": [1], \"MAX_ITER\": [100, 200, 500, 1000]}, \"M_LOGR_Classifier\": {\"MAX_ITERATION\": [100], \"ENET_ALPHA\": [0.0, 1.0], \"ENET_LAMBDA\": [0.0001, 0.001, 0.01, 0.1, 1.0, 5.0, 10.0]}, \"NB_Classifier\": {\"LAPLACE\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, \"RDT_Classifier\": {\"TREES_NUM\": [100], \"NODE_SIZE\": {\"range\": [1, 1, 6]}, \"CALCULATE_OOB\": [0], \"SAMPLE_FRACTION\": [0.75, 1.0], \"MAX_DEPTH\": [4, 10]}, \"SCALE\": {\"SCALING_METHOD\": [0, 1, 2], \"NEW_MIN\": {\"range\": [0.0, 1.0, 4.0]}, \"NEW_RANGE\": [1.0, 2.0, 3.0], \"Z-SCORE_METHOD\": [0, 1, 2]}, \"DT_Classifier\": {\"ALGORITHM\": [1, 2, 3], \"MAX_DEPTH\": {\"range\": [1, 1, 11]}, \"MIN_RECORDS_OF_PARENT\": {\"range\": [2, 1, 10]}, \"MIN_RECORDS_OF_LEAF\": {\"range\": [1, 1, 10]}}, \"SAMPLING\": {\"SAMPLING_METHOD\": [0, 1, 2, 3, 4, 5, 6], \"PERCENTAGE\": {\"range\": [0.1, 0.1, 0.9]}, \"INTERVAL\": {\"range\": [2, 1, 10]}}, \"SMOTE\": {\"K_NEAREST_NEIGHBOURS\": [1, 3], \"METHOD\": [1]}, \"SMOTETomek\": {\"K_NEAREST_NEIGHBOURS\": [1, 3], \"METHOD\": [1], \"SAMPLING_STRATEGY\": [0, 1, 2, 3]}, \"TomekLinks\": {\"SAMPLING_STRATEGY\": [0, 1, 2, 3], \"DISTANCE_LEVEL\": [2], \"METHOD\": [1]}}';\n",
      "param_name[5] := N'PIPELINE_TYPE';\n",
      "int_value[5] := NULL;\n",
      "double_value[5] := NULL;\n",
      "string_value[5] := N'classifier';\n",
      "param_name[6] := N'MAX_EVAL_TIME_MINS';\n",
      "int_value[6] := NULL;\n",
      "double_value[6] := 10;\n",
      "string_value[6] := NULL;\n",
      "param_name[7] := N'SUCCESSIVE_HALVING';\n",
      "int_value[7] := 1;\n",
      "double_value[7] := NULL;\n",
      "string_value[7] := NULL;\n",
      "param_name[8] := N'RETENTION_PERIOD';\n",
      "int_value[8] := 0;\n",
      "double_value[8] := NULL;\n",
      "string_value[8] := NULL;\n",
      "param_name[9] := N'HAS_ID';\n",
      "int_value[9] := 1;\n",
      "double_value[9] := NULL;\n",
      "string_value[9] := NULL;\n",
      "params = UNNEST(:param_name, :int_value, :double_value, :string_value);\n",
      "in_0 = SELECT \"ID\", \"SEPALLENGTHCM\", \"SEPALWIDTHCM\", \"PETALLENGTHCM\", \"PETALWIDTHCM\", \"SPECIES\" FROM (SELECT * FROM \"iris\") AS \"DT_23\";\n",
      "CALL _SYS_AFL.PAL_AUTOML_FIT(:in_0, :params, out_0, out_1, out_2);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_AUTOML_BEST_PIPELINE_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9\" AS (SELECT * FROM :out_0);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_AUTOML_MODEL_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9\" AS (SELECT * FROM :out_1);\n",
      "CREATE LOCAL TEMPORARY COLUMN TABLE \"#PAL_AUTOML_INFO_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9\" AS (SELECT * FROM :out_2);\n",
      "END WITH HINT (WORKLOAD_CLASS(\"WORKLOAD_CLASS\"))\n",
      "\n",
      "INFO:httpx:HTTP Request: POST https://api.ai.internalprod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d0eb1cc3bcf74d77/chat/completions?api-version=2023-09-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[Prompt] Fields: key: ID\n",
      "label: SPECIES\n",
      ". The user question is \"traing the model\". Please refer to the code template: \n",
      "Strictly use the Examples to create AutoML instance.\n",
      "Do fitting:\n",
      ">>> from hana_ml.algorithms.pal.auto_ml import AutomaticClassification\n",
      ">>> model_train = AutomaticClassification(generations=2, population_size=5, offspring_size=5, max_eval_time_mins=10, successive_halving=True)\n",
      ">>> model.enable_workload_class(workload_class_name=<WORKLOAD_CLASS>)\n",
      ">>> model_train.fit(data=df, key=<key>, features=<features>, label=<label>)\n",
      ">>> print({\"output table names\": model_train._fit_output_table_names, \"Python object address\": id(model_train)})\u001b[0m\n",
      "\u001b[92m[AI] Executing code...\u001b[0m \u001b[91m{'output table names': ['#PAL_AUTOML_BEST_PIPELINE_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9', '#PAL_AUTOML_MODEL_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9', '#PAL_AUTOML_INFO_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9'], 'Python object address': 2335890900240}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from generative_ai_toolkit_for_sap_hana_cloud.agents.hana_dataframe_agent import create_hana_dataframe_agent\n",
    "from generative_ai_toolkit_for_sap_hana_cloud.agents.scenario_utility import execute_code_with_fields\n",
    "\n",
    "\n",
    "agent = create_hana_dataframe_agent(llm=llm, df=connection_context.table(scenario_details[\"dataset_table\"]))\n",
    "\n",
    "query = \"traing the model\"\n",
    "result = execute_code_with_fields(agent, query, parameters_details, code_template, is_wait_for_rate_limit=True, verbose=True, show_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output table names': ['#PAL_AUTOML_BEST_PIPELINE_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9', '#PAL_AUTOML_MODEL_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9', '#PAL_AUTOML_INFO_TBL_0_3E6D3466_C1D6_11EF_B714_A84A633567F9'], 'Python object address': 2335890900240}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
